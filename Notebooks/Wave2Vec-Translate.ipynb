{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dEKhPSO82y85",
   "metadata": {
    "id": "dEKhPSO82y85"
   },
   "source": [
    "## 0. Configuartion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worthy-resolution",
   "metadata": {
    "id": "worthy-resolution"
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "import os\n",
    "import sys\n",
    "\n",
    "device = 'cuda'\n",
    "wait_for_v100 = False\n",
    "ds_to_use = [\n",
    "    'HP1-FvM',\n",
    "    # 'HP1-RB',\n",
    "    # 'HP2-FvM',\n",
    "    # 'HP2-RB',\n",
    "    # 'HP3-FvM',\n",
    "    # 'HP3-RB',\n",
    "    # 'HP4-FvM',\n",
    "    # 'HP4-RB',\n",
    "    # 'HP5-FvM',\n",
    "    # 'HP5-RB',\n",
    "    # 'HP6-FvM',\n",
    "    # 'HP6-RB',\n",
    "    # 'HP7-FvM',\n",
    "    # 'HP7-RB'\n",
    "]\n",
    "home = os.getenv(\"HOME\")\n",
    "use_gdrive = False\n",
    "trained_model_directory = 'trained_model'\n",
    "# Use Model from Checkpoint. \n",
    "# The Value must be a Sub-Directory of {trained_model_path} (Example: 'checkpoint-3600')\n",
    "checkpoint = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-budapest",
   "metadata": {
    "id": "motivated-budapest"
   },
   "source": [
    "## 1. Setup Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stuffed-silicon",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48755,
     "status": "ok",
     "timestamp": 1620812177354,
     "user": {
      "displayName": "Elius Tibelius",
      "photoUrl": "",
      "userId": "00452752923460326984"
     },
     "user_tz": -120
    },
    "id": "stuffed-silicon",
    "outputId": "022a280e-ada5-49f2-fe80-2bd02775ed95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runs on colab: False\n"
     ]
    }
   ],
   "source": [
    "local_nlp_base_dir = f'{home}/shared'\n",
    "local_data_base_dir = f'{local_nlp_base_dir}/NLP-Data'\n",
    "local_data_dir = f'{local_data_base_dir}/audio'\n",
    "extern_nlp_base_dir = None\n",
    "extern_data_base_dir = None\n",
    "extern_data_dir = None\n",
    "\n",
    "runs_on_colab = (home == '/root')\n",
    "print( f'runs on colab: {runs_on_colab}')\n",
    "\n",
    "if not runs_on_colab:\n",
    "    os.environ['http_proxy'] = 'http://192.168.8.50:3128'\n",
    "    os.environ['https_proxy'] = 'http://192.168.8.50:3128'\n",
    "else:\n",
    "    # to get access to the datasets we use gdrive\n",
    "    use_gdrive = True\n",
    "    # install packages\n",
    "    !pip install datasets==1.4.1\n",
    "    !pip install transformers==4.4.0\n",
    "    !pip install jiwer\n",
    "    !pip install torchaudio\n",
    "    !pip install librosa\n",
    "    # create local directories\n",
    "    !mkdir $local_nlp_base_dir\n",
    "    !mkdir $local_data_base_dir\n",
    "\n",
    "if use_gdrive:\n",
    "    gdrive_base = '/content/gdrive'    \n",
    "    extern_nlp_base_dir = f'{gdrive_base}/MyDrive'\n",
    "    extern_data_base_dir = f'{extern_nlp_base_dir}/NLP-Data'\n",
    "    extern_data_dir = f'{extern_data_base_dir}/audio'\n",
    "\n",
    "    if not os.path.isdir(gdrive_base):\n",
    "        from google.colab import drive\n",
    "        drive.mount(gdrive_base)\n",
    "\n",
    "if not os.path.isdir(local_data_dir):\n",
    "    !mkdir $local_data_dir\n",
    "\n",
    "if extern_nlp_base_dir:\n",
    "    model_dir = f'{extern_nlp_base_dir}/NLP-Models/GermanWave2Vec'\n",
    "else:\n",
    "    model_dir = f'{local_nlp_base_dir}/NLP-Models/GermanWave2Vec'\n",
    "\n",
    "# Use the Model from this Directory (Base: .../NLP-Models/GermanWave2Vec/)\n",
    "# None -> Start from 'facebook/wav2vec2-large-xlsr-53-german'\n",
    "trained_model_path = f'{model_dir}/{trained_model_directory}'\n",
    "\n",
    "git_views_dir = f'{local_nlp_base_dir}/gitviews/extern'\n",
    "git_view_path = f'{git_views_dir}/GermanWave2Vec'\n",
    "\n",
    "if not os.path.isdir(git_views_dir):\n",
    "    !mkdir $git_views_dir\n",
    "    !cd $git_views_dir; git clone https://github.com/ElUnrast/GermanWave2Vec.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4wLJpgjxOFRM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1773,
     "status": "ok",
     "timestamp": 1620812249370,
     "user": {
      "displayName": "Elius Tibelius",
      "photoUrl": "",
      "userId": "00452752923460326984"
     },
     "user_tz": -120
    },
    "id": "4wLJpgjxOFRM",
    "outputId": "48670cda-fe17-40f7-d7ad-967f07b28354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script-Path: /home/ki-mo/shared/gitviews/extern/GermanWave2Vec/python\n"
     ]
    }
   ],
   "source": [
    "if runs_on_colab:\n",
    "    !cd $git_view_path; git fetch --all; git reset --hard origin/main\n",
    "\n",
    "script_path = f'{git_views_dir}/GermanWave2Vec/python'\n",
    "print(f'Script-Path: {script_path}')\n",
    "sys.path.insert(0, script_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-footwear",
   "metadata": {
    "id": "better-footwear"
   },
   "source": [
    "## 2. Check Runtime Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accompanied-wright",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1620812267985,
     "user": {
      "displayName": "Elius Tibelius",
      "photoUrl": "",
      "userId": "00452752923460326984"
     },
     "user_tz": -120
    },
    "id": "accompanied-wright",
    "outputId": "a6984eb8-cb57-4fa0-8dae-f817850837ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 31 09:34:30 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 35%   36C    P8    12W / 260W |     92MiB / 11016MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1134      G   /usr/lib/xorg/Xorg                 26MiB |\n",
      "|    0   N/A  N/A      1236      G   /usr/bin/gnome-shell               63MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "if 'cuda' == device:\n",
    "    gpu_info = !nvidia-smi\n",
    "    gpu_info = '\\n'.join(gpu_info)\n",
    "\n",
    "    if runs_on_colab:\n",
    "        if wait_for_v100 and not gpu_info.find('V100') >= 0:\n",
    "            print('The current GPU is not a V100')\n",
    "            print('Since you want to wait for a V100 the current session is aborted')\n",
    "            raise ValueError\n",
    "\n",
    "        if gpu_info.find('failed') >= 0:\n",
    "            print('For training, please use a VM with GPU!')\n",
    "            raise ValueError\n",
    "            \n",
    "        from psutil import virtual_memory\n",
    "        ram_gb = virtual_memory().total / 1e9\n",
    "        print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "        if ram_gb < 20:\n",
    "            print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "            print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "            print('re-execute this cell.')\n",
    "        else:\n",
    "            print('You are using a high-RAM runtime!')\n",
    "            \n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-liver",
   "metadata": {
    "id": "connected-liver"
   },
   "source": [
    "## 3 Install packages and do Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "copyrighted-peeing",
   "metadata": {
    "id": "copyrighted-peeing"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_utils import get_last_checkpoint, is_main_process\n",
    "from transformers.trainer_pt_utils import LengthGroupedSampler, DistributedLengthGroupedSampler\n",
    "\n",
    "import json\n",
    "import collections\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import jiwer\n",
    "from jiwer import wer\n",
    "from datasets import load_metric\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7desxN6tZVU3",
   "metadata": {
    "id": "7desxN6tZVU3"
   },
   "outputs": [],
   "source": [
    "# %aimport SnippetDatasets\n",
    "# %aimport GermanSpeechDatasetWidgetFactory\n",
    "# %aimport GermanSpeechToTextTranslater\n",
    "# %autoreload 2\n",
    "from SnippetDatasets import SnippetDatasets\n",
    "from GermanSpeechDatasetWidgetFactory import GermanSpeechDatasetWidgetFactory\n",
    "from GermanSpeechToTextTranslater import GermanSpeechToTextTranslater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-singing",
   "metadata": {
    "id": "certified-singing"
   },
   "source": [
    "## 4 Initialize Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unexpected-ideal",
   "metadata": {
    "id": "unexpected-ideal",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_datasets = SnippetDatasets(\n",
    "    runs_on_colab, \n",
    "    local_audio_base_dir=local_data_dir, \n",
    "    git_repository=git_view_path,\n",
    "    extern_audio_base_dir=extern_data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "measured-craps",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151,
     "referenced_widgets": [
      "7b46e89a13764745915b7802aaedc5ee",
      "7d8e46c71b3e45cfa775157a66ac5a52",
      "78f2db221c504bfeb80d08123dde7808",
      "03c3d21fb26343a8b6fec43119e854ce",
      "449bce20528d4f0fa84a533edf31868f",
      "f6212268701e4b5485254734029c7eda",
      "da0a96e9b4194da4b5b242dc2d716bd9",
      "03ea4a943dfa478e9a1a87e251c05af6"
     ]
    },
    "executionInfo": {
     "elapsed": 77594,
     "status": "ok",
     "timestamp": 1620812368354,
     "user": {
      "displayName": "Elius Tibelius",
      "photoUrl": "",
      "userId": "00452752923460326984"
     },
     "user_tz": -120
    },
    "id": "measured-craps",
    "outputId": "e7a3968e-7107-4634-eab1-9ec5a4a2e424",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Model from Path: /home/ki-mo/shared/NLP-Models/GermanWave2Vec/trained_model\n",
      "Using Model: /home/ki-mo/shared/NLP-Models/GermanWave2Vec/trained_model\n",
      "Loading processor\n",
      "Loading metric\n",
      "json loaded: {'trained_epochs': 118}\n",
      "Saved Epoch: 118\n",
      "Loading model. Epoche 118\n"
     ]
    }
   ],
   "source": [
    "model_path = None\n",
    "\n",
    "if checkpoint:\n",
    "    model_path = f'{trained_model_path}/{checkpoint}'\n",
    "elif os.path.isfile(f'{trained_model_path}/pytorch_model.bin'):\n",
    "    model_path = trained_model_path\n",
    "\n",
    "print(f'Initialize Model from Path: {model_path}')\n",
    "translator = GermanSpeechToTextTranslater(model_name=model_path, ds_handler=my_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XHvPPiWru_IC",
   "metadata": {
    "id": "XHvPPiWru_IC"
   },
   "source": [
    "## 5. Choose Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "A2FODbnsFmoC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 890,
     "status": "error",
     "timestamp": 1620852931702,
     "user": {
      "displayName": "Elius Tibelius",
      "photoUrl": "",
      "userId": "00452752923460326984"
     },
     "user_tz": -120
    },
    "id": "A2FODbnsFmoC",
    "outputId": "ce71c4b2-5ec1-41e9-a7cb-6ba14db9178d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose Datasets to use\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170f3d3df2f74b639bbc459bf6e237ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Checkbox(value=True, description='HP1-FvM', indent=False), Checkbox(value=False, description='HP…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget_factory = GermanSpeechDatasetWidgetFactory(my_datasets, ds_to_use)\n",
    "print('Please choose Datasets to use')\n",
    "ds_checkboxes_widget = widget_factory.create_dataset_choice_widget()\n",
    "display(ds_checkboxes_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-trace",
   "metadata": {},
   "source": [
    "## 6. Test and update Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-found",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset: HP1-FvM\n",
      "-----------------------------\n",
      "Loading Dataset: HP1-FvM - content-translated-with_original.csv\n",
      "Pruning Dataset HP1-FvM with 8055 Entries\n",
      " - 8055 Entries left after Length Cut (min=31, max=4000)\n",
      " - 8055 Entries left after Action Cut\n",
      "aktual trained epoches: 118\n",
      "old trained epoches: 118\n",
      "Loading Dataset: HP2-FvM\n",
      "-----------------------------\n",
      "Loading Dataset: HP2-FvM - content-translated-with_original.csv\n",
      "Pruning Dataset HP2-FvM with 10892 Entries\n",
      " - 10892 Entries left after Length Cut (min=31, max=4000)\n",
      " - 10892 Entries left after Action Cut\n",
      "aktual trained epoches: 118\n",
      "old trained epoches: 1\n",
      "Translate all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e146f64c20964031a6a9730935484236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10892.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculate WER\n",
      "WER: 0.014775455032743714\n",
      "No. of bad translated snippets: 664\n",
      "Saving diff files\n",
      "Loading Dataset: HP3-FvM\n",
      "-----------------------------\n",
      "Loading Dataset: HP3-FvM - content-translated-with_original.csv\n",
      "Pruning Dataset HP3-FvM with 13161 Entries\n",
      " - 13161 Entries left after Length Cut (min=31, max=4000)\n",
      " - 13161 Entries left after Action Cut\n",
      "aktual trained epoches: 118\n",
      "old trained epoches: 1\n",
      "Translate all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888fe5cb4d9d4e278d7b0ede2818fbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculate WER\n",
      "WER: 0.01012037532029421\n",
      "No. of bad translated snippets: 624\n",
      "Saving diff files\n",
      "Loading Dataset: HP4-FvM\n",
      "-----------------------------\n",
      "Loading Dataset: HP4-FvM - content-translated-with_original.csv\n",
      "Pruning Dataset HP4-FvM with 23579 Entries\n",
      " - 23579 Entries left after Length Cut (min=31, max=4000)\n",
      " - 23579 Entries left after Action Cut\n",
      "aktual trained epoches: 118\n",
      "old trained epoches: 1\n",
      "Translate all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c993a5fa84944ad9880aae27f33e0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23579.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculate WER\n",
      "WER: 0.01154486963136776\n",
      "No. of bad translated snippets: 980\n",
      "Saving diff files\n",
      "Loading Dataset: HP5-FvM\n",
      "-----------------------------\n",
      "Loading Dataset: HP5-FvM - content-translated-with_original.csv\n",
      "Pruning Dataset HP5-FvM with 31823 Entries\n",
      " - 31823 Entries left after Length Cut (min=31, max=4000)\n",
      " - 31823 Entries left after Action Cut\n",
      "aktual trained epoches: 118\n",
      "old trained epoches: 0\n",
      "Saving word_error_rate: 2.936442182506805\n",
      "Translate all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cbaceb76744db08af28e46f8e770c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31823.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculate WER\n",
      "WER: 0.006556988992780211\n",
      "No. of bad translated snippets: 1058\n",
      "Saving diff files\n",
      "Loading Dataset: HP6-FvM\n",
      "-----------------------------\n",
      "Loading Dataset: HP6-FvM - content-translated-with_original.csv\n",
      "Pruning Dataset HP6-FvM with 20319 Entries\n",
      " - 20319 Entries left after Length Cut (min=31, max=4000)\n",
      " - 20319 Entries left after Action Cut\n",
      "aktual trained epoches: 118\n",
      "old trained epoches: 1\n",
      "Translate all\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97eff8da98424f1f81785c14a9179ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20319.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ds_id in widget_factory.get_used_datasets():\n",
    "    translator.test(ds_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rPHzCcxaYJAz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1620853210989,
     "user": {
      "displayName": "Elius Tibelius",
      "photoUrl": "",
      "userId": "00452752923460326984"
     },
     "user_tz": -120
    },
    "id": "rPHzCcxaYJAz",
    "outputId": "541ea6e0-2a5a-4ed9-a7c8-73b876f1fe89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display:none\">\n",
       "                <audio onended=\"this.parentNode.removeChild(this)\"  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.w3schools.com/html/horse.ogg\" type=\"audio/ogg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              </div>"
      ],
      "text/plain": [
       "<GermanSpeechDatasetWidgetFactory.InvisibleAudio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('finished')\n",
    "widget_factory.play_audio_file(audio_url=\"http://www.w3schools.com/html/horse.ogg\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "better-footwear"
   ],
   "name": "Wave2Vec-Train.ipynb",
   "provenance": [
    {
     "file_id": "18nAJ5oJgm56etRE3MTVNC4ofrVNHgEQG",
     "timestamp": 1621004295534
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03c3d21fb26343a8b6fec43119e854ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03ea4a943dfa478e9a1a87e251c05af6",
      "placeholder": "​",
      "style": "IPY_MODEL_da0a96e9b4194da4b5b242dc2d716bd9",
      "value": " 3.90k/? [00:00&lt;00:00, 15.9kB/s]"
     }
    },
    "03ea4a943dfa478e9a1a87e251c05af6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "449bce20528d4f0fa84a533edf31868f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "78f2db221c504bfeb80d08123dde7808": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6212268701e4b5485254734029c7eda",
      "max": 1764,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_449bce20528d4f0fa84a533edf31868f",
      "value": 1764
     }
    },
    "7b46e89a13764745915b7802aaedc5ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78f2db221c504bfeb80d08123dde7808",
       "IPY_MODEL_03c3d21fb26343a8b6fec43119e854ce"
      ],
      "layout": "IPY_MODEL_7d8e46c71b3e45cfa775157a66ac5a52"
     }
    },
    "7d8e46c71b3e45cfa775157a66ac5a52": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da0a96e9b4194da4b5b242dc2d716bd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6212268701e4b5485254734029c7eda": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
